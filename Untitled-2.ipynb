{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13a20706",
   "metadata": {},
   "source": [
    "# Credit Risk Classification with Advanced Visualizations\n",
    "## Comprehensive Data Analysis, Feature Engineering, and Model Optimization\n",
    "### Enhanced with Detailed Data Visualizations and Statistical Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c8b1de",
   "metadata": {},
   "source": [
    "## Section 1: Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b534e185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import time\n",
    "\n",
    "# Machine learning models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Preprocessing and pipeline utilities\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Hyperparameter optimization\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform, randint\n",
    "\n",
    "# Evaluation metrics\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, roc_auc_score, f1_score, confusion_matrix, \n",
    "    classification_report, roc_curve, precision_score, recall_score\n",
    ")\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for better visualizations\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "print(\"✓ All libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3c1861",
   "metadata": {},
   "source": [
    "## Section 2: Load and Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7752d6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define column names\n",
    "column_names = [\n",
    "    'Status_Checking_Account', 'Duration_Months', 'Credit_History', 'Purpose', \n",
    "    'Credit_Amount', 'Savings_Account', 'Employment_Since', 'Installment_Rate', \n",
    "    'Gender_Status', 'Other_Debtors', 'Residence_Years', 'Property', 'Age', \n",
    "    'Other_Installments', 'Housing', 'Existing_Credits', 'Job', 'Dependents', \n",
    "    'Telephone', 'Foreign_Worker', 'Credit_Risk'\n",
    "]\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('SouthGermanCredit.asc', delim_whitespace=True, header=0, names=column_names)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"DATASET OVERVIEW\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(df.head())\n",
    "print(f\"\\nData types:\")\n",
    "print(df.dtypes)\n",
    "print(f\"\\nBasic statistics:\")\n",
    "print(df.describe())\n",
    "print(f\"\\nMissing values:\")\n",
    "print(df.isnull().sum().sum(), \"total missing values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f61b70",
   "metadata": {},
   "source": [
    "## Section 3: Target Distribution Visualization\n",
    "### Analyzing Credit Risk Class Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1705fd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target distribution analysis\n",
    "target_counts = df['Credit_Risk'].value_counts()\n",
    "target_pct = df['Credit_Risk'].value_counts(normalize=True) * 100\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TARGET DISTRIBUTION ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nClass counts:\")\n",
    "print(f\"  Class 0 (Good Credit): {target_counts[0]} ({target_pct[0]:.2f}%)\")\n",
    "print(f\"  Class 1 (Bad Credit):  {target_counts[1]} ({target_pct[1]:.2f}%)\")\n",
    "print(f\"\\nClass Imbalance Ratio: {target_counts[0]/target_counts[1]:.2f}:1\")\n",
    "print(f\"Minority class percentage: {target_pct[1]:.2f}%\")\n",
    "\n",
    "# Create comprehensive target distribution visualizations\n",
    "fig = plt.figure(figsize=(16, 10))\n",
    "\n",
    "# 1. Count plot\n",
    "ax1 = plt.subplot(2, 3, 1)\n",
    "colors = ['#2ecc71', '#e74c3c']\n",
    "bars = ax1.bar(['Good Credit (0)', 'Bad Credit (1)'], target_counts.values, color=colors, alpha=0.8, edgecolor='black', linewidth=2)\n",
    "ax1.set_ylabel('Count', fontsize=12, fontweight='bold')\n",
    "ax1.set_title('Credit Risk Distribution - Count', fontsize=13, fontweight='bold')\n",
    "ax1.grid(alpha=0.3, axis='y')\n",
    "for i, bar in enumerate(bars):\n",
    "    height = bar.get_height()\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'{int(height)}\\n({target_pct.values[i]:.1f}%)',\n",
    "            ha='center', va='bottom', fontweight='bold', fontsize=11)\n",
    "\n",
    "# 2. Percentage distribution bar\n",
    "ax2 = plt.subplot(2, 3, 2)\n",
    "bars = ax2.bar(['Good Credit (0)', 'Bad Credit (1)'], target_pct.values, color=colors, alpha=0.8, edgecolor='black', linewidth=2)\n",
    "ax2.set_ylabel('Percentage (%)', fontsize=12, fontweight='bold')\n",
    "ax2.set_title('Credit Risk Distribution - Percentage', fontsize=13, fontweight='bold')\n",
    "ax2.set_ylim(0, 100)\n",
    "ax2.grid(alpha=0.3, axis='y')\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'{height:.1f}%',\n",
    "            ha='center', va='bottom', fontweight='bold', fontsize=11)\n",
    "\n",
    "# 3. Pie chart with percentage\n",
    "ax3 = plt.subplot(2, 3, 3)\n",
    "explode = (0.05, 0.1)\n",
    "wedges, texts, autotexts = ax3.pie(target_pct.values, labels=['Good Credit (0)', 'Bad Credit (1)'],\n",
    "                                     autopct='%1.1f%%', colors=colors, explode=explode,\n",
    "                                     startangle=90, textprops={'fontsize': 11, 'fontweight': 'bold'},\n",
    "                                     wedgeprops={'edgecolor': 'black', 'linewidth': 2})\n",
    "ax3.set_title('Credit Risk Distribution - Pie Chart', fontsize=13, fontweight='bold')\n",
    "\n",
    "# 4. Imbalance ratio visualization\n",
    "ax4 = plt.subplot(2, 3, 4)\n",
    "imbalance_ratio = target_counts[0] / target_counts[1]\n",
    "ax4.barh(['Imbalance Ratio'], [imbalance_ratio], color='#3498db', alpha=0.8, edgecolor='black', linewidth=2)\n",
    "ax4.set_xlabel('Ratio (Good:Bad)', fontsize=12, fontweight='bold')\n",
    "ax4.set_title(f'Class Imbalance Ratio: {imbalance_ratio:.2f}:1', fontsize=13, fontweight='bold')\n",
    "ax4.set_xlim(0, imbalance_ratio + 0.5)\n",
    "ax4.text(imbalance_ratio/2, 0, f'{imbalance_ratio:.2f}:1', \n",
    "         ha='center', va='center', fontweight='bold', fontsize=14, color='white')\n",
    "ax4.grid(alpha=0.3, axis='x')\n",
    "\n",
    "# 5. Stacked bar showing proportions\n",
    "ax5 = plt.subplot(2, 3, 5)\n",
    "ax5.barh(['Distribution'], [target_pct[0]], label='Good Credit (0)', color=colors[0], alpha=0.8, edgecolor='black', linewidth=2)\n",
    "ax5.barh(['Distribution'], [target_pct[1]], left=[target_pct[0]], label='Bad Credit (1)', color=colors[1], alpha=0.8, edgecolor='black', linewidth=2)\n",
    "ax5.set_xlabel('Percentage (%)', fontsize=12, fontweight='bold')\n",
    "ax5.set_title('Stacked Distribution', fontsize=13, fontweight='bold')\n",
    "ax5.legend(loc='upper right', fontsize=10)\n",
    "ax5.set_xlim(0, 100)\n",
    "for i, pct in enumerate(target_pct.values):\n",
    "    if i == 0:\n",
    "        ax5.text(pct/2, 0, f'{pct:.1f}%', ha='center', va='center', fontweight='bold', fontsize=11, color='white')\n",
    "    else:\n",
    "        ax5.text(target_pct[0] + pct/2, 0, f'{pct:.1f}%', ha='center', va='center', fontweight='bold', fontsize=11, color='white')\n",
    "\n",
    "# 6. Summary table\n",
    "ax6 = plt.subplot(2, 3, 6)\n",
    "ax6.axis('off')\n",
    "summary_data = [\n",
    "    ['Metric', 'Value'],\n",
    "    ['Total Samples', f'{len(df):,}'],\n",
    "    ['Good Credit', f'{target_counts[0]:,} ({target_pct[0]:.2f}%)'],\n",
    "    ['Bad Credit', f'{target_counts[1]:,} ({target_pct[1]:.2f}%)'],\n",
    "    ['Imbalance Ratio', f'{imbalance_ratio:.2f}:1'],\n",
    "    ['Minority Class %', f'{target_pct[1]:.2f}%'],\n",
    "]\n",
    "table = ax6.table(cellText=summary_data, cellLoc='center', loc='center',\n",
    "                  colWidths=[0.4, 0.6], bbox=[0, 0, 1, 1])\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(11)\n",
    "table.scale(1, 2.5)\n",
    "for i in range(len(summary_data)):\n",
    "    for j in range(2):\n",
    "        cell = table[(i, j)]\n",
    "        if i == 0:\n",
    "            cell.set_facecolor('#34495e')\n",
    "            cell.set_text_props(weight='bold', color='white')\n",
    "        else:\n",
    "            cell.set_facecolor('#ecf0f1' if i % 2 == 0 else '#ffffff')\n",
    "            cell.set_text_props(weight='bold' if j == 0 else 'normal')\n",
    "ax6.set_title('Summary Statistics', fontsize=13, fontweight='bold', pad=20)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('01_target_distribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Target distribution visualizations created successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6a4014",
   "metadata": {},
   "source": [
    "## Section 4: Numerical Features Distribution Analysis\n",
    "### Detecting Skewness and Identifying Scaling Necessity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b591da05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify numerical features\n",
    "numerical_features = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "numerical_features.remove('Credit_Risk')\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"NUMERICAL FEATURES DISTRIBUTION ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nNumerical features to analyze: {len(numerical_features)}\")\n",
    "print(f\"Features: {numerical_features}\")\n",
    "\n",
    "# Calculate skewness and kurtosis\n",
    "skewness_data = []\n",
    "for col in numerical_features:\n",
    "    skew = stats.skew(df[col])\n",
    "    kurt = stats.kurtosis(df[col])\n",
    "    skewness_data.append({'Feature': col, 'Skewness': skew, 'Kurtosis': kurt})\n",
    "\n",
    "skewness_df = pd.DataFrame(skewness_data).sort_values('Skewness', key=abs, ascending=False)\n",
    "print(f\"\\nSkewness and Kurtosis Analysis:\")\n",
    "print(skewness_df.to_string(index=False))\n",
    "\n",
    "# Create comprehensive distribution visualizations\n",
    "fig = plt.figure(figsize=(18, 12))\n",
    "\n",
    "# Select top numerical features for visualization\n",
    "top_features = ['Credit_Amount', 'Duration_Months', 'Age', 'Credit_History', \n",
    "                'Installment_Rate', 'Residence_Years']\n",
    "\n",
    "for idx, feature in enumerate(top_features):\n",
    "    # Histogram with KDE\n",
    "    ax = plt.subplot(3, 4, idx + 1)\n",
    "    data = df[feature].dropna()\n",
    "    \n",
    "    n, bins, patches = ax.hist(data, bins=30, color='#3498db', alpha=0.7, edgecolor='black', density=True)\n",
    "    \n",
    "    # Add KDE overlay\n",
    "    from scipy.stats import gaussian_kde\n",
    "    kde = gaussian_kde(data)\n",
    "    x_range = np.linspace(data.min(), data.max(), 100)\n",
    "    ax.plot(x_range, kde(x_range), 'r-', linewidth=2, label='KDE')\n",
    "    \n",
    "    ax.set_xlabel(feature, fontsize=10, fontweight='bold')\n",
    "    ax.set_ylabel('Density', fontsize=10, fontweight='bold')\n",
    "    ax.set_title(f'{feature} Distribution', fontsize=11, fontweight='bold')\n",
    "    ax.grid(alpha=0.3)\n",
    "    ax.legend()\n",
    "    \n",
    "    # Add skewness info\n",
    "    skew_val = stats.skew(data)\n",
    "    ax.text(0.98, 0.97, f'Skewness: {skew_val:.3f}', \n",
    "            transform=ax.transAxes, ha='right', va='top',\n",
    "            bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8),\n",
    "            fontsize=9, fontweight='bold')\n",
    "\n",
    "# Box plots for outlier detection\n",
    "for idx, feature in enumerate(top_features):\n",
    "    ax = plt.subplot(3, 4, 6 + idx + 1)\n",
    "    \n",
    "    bp = ax.boxplot([df[feature].dropna()], vert=True, patch_artist=True,\n",
    "                     labels=[feature], widths=0.6,\n",
    "                     boxprops=dict(facecolor='#2ecc71', alpha=0.7, edgecolor='black', linewidth=1.5),\n",
    "                     whiskerprops=dict(color='black', linewidth=1.5),\n",
    "                     capprops=dict(color='black', linewidth=1.5),\n",
    "                     medianprops=dict(color='red', linewidth=2),\n",
    "                     flierprops=dict(marker='o', markerfacecolor='#e74c3c', markersize=5, alpha=0.5))\n",
    "    \n",
    "    ax.set_ylabel('Value', fontsize=10, fontweight='bold')\n",
    "    ax.set_title(f'{feature} Box Plot', fontsize=11, fontweight='bold')\n",
    "    ax.grid(alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('02_numerical_distribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✓ Numerical distribution visualizations created successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7271325",
   "metadata": {},
   "source": [
    "## Section 5: Categorical Features Distribution Analysis\n",
    "### Exhibiting Category Distributions and Identifying Imbalances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c47022e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify categorical features\n",
    "categorical_features = df.select_dtypes(include=['object']).columns.tolist()\n",
    "# For integer columns that are categorical\n",
    "categorical_int_features = ['Status_Checking_Account', 'Credit_History', 'Purpose', \n",
    "                            'Savings_Account', 'Employment_Since', 'Installment_Rate',\n",
    "                            'Gender_Status', 'Other_Debtors', 'Property', 'Other_Installments',\n",
    "                            'Housing', 'Existing_Credits', 'Job', 'Dependents', 'Telephone',\n",
    "                            'Foreign_Worker']\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CATEGORICAL FEATURES DISTRIBUTION ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nCategorical features to analyze: {len(categorical_int_features)}\")\n",
    "\n",
    "# Create comprehensive categorical visualizations\n",
    "fig = plt.figure(figsize=(20, 14))\n",
    "\n",
    "# Select key categorical features\n",
    "key_categorical = ['Purpose', 'Status_Checking_Account', 'Savings_Account', \n",
    "                   'Employment_Since', 'Housing', 'Credit_History']\n",
    "\n",
    "for idx, feature in enumerate(key_categorical):\n",
    "    ax = plt.subplot(3, 3, idx + 1)\n",
    "    \n",
    "    value_counts = df[feature].value_counts().sort_values(ascending=False)\n",
    "    \n",
    "    # Create count plot\n",
    "    bars = ax.bar(range(len(value_counts)), value_counts.values, \n",
    "                  color=plt.cm.Set3(np.linspace(0, 1, len(value_counts))),\n",
    "                  alpha=0.8, edgecolor='black', linewidth=1.5)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for i, bar in enumerate(bars):\n",
    "        height = bar.get_height()\n",
    "        pct = (height / df.shape[0]) * 100\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "               f'{int(height)}\\n({pct:.1f}%)',\n",
    "               ha='center', va='bottom', fontsize=9, fontweight='bold')\n",
    "    \n",
    "    ax.set_xticks(range(len(value_counts)))\n",
    "    ax.set_xticklabels(value_counts.index, rotation=45, ha='right', fontsize=9)\n",
    "    ax.set_ylabel('Count', fontsize=10, fontweight='bold')\n",
    "    ax.set_title(f'{feature} Distribution', fontsize=11, fontweight='bold')\n",
    "    ax.grid(alpha=0.3, axis='y')\n",
    "\n",
    "# Overall categorical feature summary\n",
    "ax_summary = plt.subplot(3, 3, 7)\n",
    "ax_summary.axis('off')\n",
    "\n",
    "summary_text = f\"\"\"\n",
    "CATEGORICAL FEATURES SUMMARY\n",
    "\n",
    "Total Categorical Features: {len(categorical_int_features)}\n",
    "\n",
    "Top 6 Features Visualized:\n",
    "{', '.join(key_categorical[:3])}\n",
    "{', '.join(key_categorical[3:])}\n",
    "\n",
    "Analysis Focus:\n",
    "• Distribution balance across categories\n",
    "• Rare categories identification\n",
    "• Potential encoding strategies\n",
    "• Feature consolidation opportunities\n",
    "\"\"\"\n",
    "\n",
    "ax_summary.text(0.05, 0.95, summary_text, transform=ax_summary.transAxes,\n",
    "               fontsize=10, verticalalignment='top', fontfamily='monospace',\n",
    "               bbox=dict(boxstyle='round', facecolor='#ecf0f1', alpha=0.8, pad=1))\n",
    "\n",
    "# Unique value counts for all categorical features\n",
    "ax_unique = plt.subplot(3, 3, 8)\n",
    "unique_counts = [df[feat].nunique() for feat in categorical_int_features]\n",
    "sorted_indices = np.argsort(unique_counts)[::-1][:10]\n",
    "top_unique_feats = [categorical_int_features[i] for i in sorted_indices]\n",
    "top_unique_counts = [unique_counts[i] for i in sorted_indices]\n",
    "\n",
    "bars = ax_unique.barh(top_unique_feats, top_unique_counts, color='#9b59b6', alpha=0.8, edgecolor='black', linewidth=1.5)\n",
    "ax_unique.set_xlabel('Number of Unique Values', fontsize=10, fontweight='bold')\n",
    "ax_unique.set_title('Top 10: Categorical Cardinality', fontsize=11, fontweight='bold')\n",
    "ax_unique.grid(alpha=0.3, axis='x')\n",
    "for i, bar in enumerate(bars):\n",
    "    width = bar.get_width()\n",
    "    ax_unique.text(width, bar.get_y() + bar.get_height()/2.,\n",
    "                  f' {int(width)}', ha='left', va='center', fontweight='bold', fontsize=9)\n",
    "\n",
    "# Missing values in categorical features\n",
    "ax_missing = plt.subplot(3, 3, 9)\n",
    "missing_counts = [df[feat].isnull().sum() for feat in categorical_int_features]\n",
    "missing_pct = [(count/len(df))*100 for count in missing_counts]\n",
    "non_zero_missing = [(feat, pct) for feat, pct in zip(categorical_int_features, missing_pct) if pct > 0]\n",
    "\n",
    "if non_zero_missing:\n",
    "    feats, pcts = zip(*non_zero_missing)\n",
    "    bars = ax_missing.barh(feats, pcts, color='#e74c3c', alpha=0.8, edgecolor='black', linewidth=1.5)\n",
    "    ax_missing.set_xlabel('Missing Percentage (%)', fontsize=10, fontweight='bold')\n",
    "    ax_missing.set_title('Missing Values in Categorical Features', fontsize=11, fontweight='bold')\n",
    "    ax_missing.grid(alpha=0.3, axis='x')\n",
    "else:\n",
    "    ax_missing.text(0.5, 0.5, 'No Missing Values', ha='center', va='center',\n",
    "                   transform=ax_missing.transAxes, fontsize=12, fontweight='bold')\n",
    "    ax_missing.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('03_categorical_distribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✓ Categorical distribution visualizations created successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa05ec24",
   "metadata": {},
   "source": [
    "## Section 6: Correlation and Multicollinearity Analysis\n",
    "### Detecting Potential Multicollinearity Issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d95024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation matrix for numerical features\n",
    "correlation_matrix = df[numerical_features].corr()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CORRELATION AND MULTICOLLINEARITY ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Find highly correlated pairs\n",
    "high_corr_pairs = []\n",
    "for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(i+1, len(correlation_matrix.columns)):\n",
    "        if abs(correlation_matrix.iloc[i, j]) > 0.7:\n",
    "            high_corr_pairs.append({\n",
    "                'Feature 1': correlation_matrix.columns[i],\n",
    "                'Feature 2': correlation_matrix.columns[j],\n",
    "                'Correlation': correlation_matrix.iloc[i, j]\n",
    "            })\n",
    "\n",
    "if high_corr_pairs:\n",
    "    high_corr_df = pd.DataFrame(high_corr_pairs).sort_values('Correlation', key=abs, ascending=False)\n",
    "    print(\"\\nHighly Correlated Feature Pairs (|r| > 0.7):\")\n",
    "    print(high_corr_df.to_string(index=False))\n",
    "else:\n",
    "    print(\"\\nNo highly correlated pairs (|r| > 0.7) found\")\n",
    "\n",
    "# Moderate correlations\n",
    "mod_corr_pairs = []\n",
    "for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(i+1, len(correlation_matrix.columns)):\n",
    "        if 0.5 <= abs(correlation_matrix.iloc[i, j]) <= 0.7:\n",
    "            mod_corr_pairs.append({\n",
    "                'Feature 1': correlation_matrix.columns[i],\n",
    "                'Feature 2': correlation_matrix.columns[j],\n",
    "                'Correlation': correlation_matrix.iloc[i, j]\n",
    "            })\n",
    "\n",
    "if mod_corr_pairs:\n",
    "    mod_corr_df = pd.DataFrame(mod_corr_pairs).sort_values('Correlation', key=abs, ascending=False)\n",
    "    print(\"\\nModerately Correlated Feature Pairs (0.5 ≤ |r| ≤ 0.7):\")\n",
    "    print(mod_corr_df.head(10).to_string(index=False))\n",
    "\n",
    "# Create visualizations\n",
    "fig = plt.figure(figsize=(18, 12))\n",
    "\n",
    "# 1. Full correlation heatmap\n",
    "ax1 = plt.subplot(2, 2, 1)\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm', center=0,\n",
    "           square=True, linewidths=0.5, cbar_kws={\"shrink\": 0.8},\n",
    "           ax=ax1, annot_kws={'fontsize': 8})\n",
    "ax1.set_title('Full Correlation Matrix - All Numerical Features', fontsize=13, fontweight='bold')\n",
    "plt.setp(ax1.get_xticklabels(), rotation=45, ha='right', fontsize=9)\n",
    "plt.setp(ax1.get_yticklabels(), rotation=0, fontsize=9)\n",
    "\n",
    "# 2. Correlation with target variable\n",
    "ax2 = plt.subplot(2, 2, 2)\n",
    "target_corr = df[numerical_features + ['Credit_Risk']].corr()['Credit_Risk'].drop('Credit_Risk').sort_values()\n",
    "colors_target = ['#e74c3c' if x > 0 else '#3498db' for x in target_corr.values]\n",
    "bars = ax2.barh(range(len(target_corr)), target_corr.values, color=colors_target, alpha=0.8, edgecolor='black', linewidth=1.5)\n",
    "ax2.set_yticks(range(len(target_corr)))\n",
    "ax2.set_yticklabels(target_corr.index, fontsize=10)\n",
    "ax2.set_xlabel('Correlation with Credit Risk', fontsize=11, fontweight='bold')\n",
    "ax2.set_title('Feature Correlation with Target Variable', fontsize=13, fontweight='bold')\n",
    "ax2.axvline(x=0, color='black', linestyle='-', linewidth=1)\n",
    "ax2.grid(alpha=0.3, axis='x')\n",
    "for i, bar in enumerate(bars):\n",
    "    width = bar.get_width()\n",
    "    ax2.text(width, bar.get_y() + bar.get_height()/2.,\n",
    "            f' {width:.3f}', ha='left' if width > 0 else 'right', \n",
    "            va='center', fontweight='bold', fontsize=9)\n",
    "\n",
    "# 3. Distribution of correlation values\n",
    "ax3 = plt.subplot(2, 2, 3)\n",
    "corr_values = correlation_matrix.values[np.triu_indices_from(correlation_matrix.values, k=1)]\n",
    "ax3.hist(corr_values, bins=30, color='#9b59b6', alpha=0.8, edgecolor='black', linewidth=1.5)\n",
    "ax3.axvline(x=0.7, color='red', linestyle='--', linewidth=2, label='High Correlation Threshold (0.7)')\n",
    "ax3.axvline(x=0.5, color='orange', linestyle='--', linewidth=2, label='Moderate Threshold (0.5)')\n",
    "ax3.set_xlabel('Correlation Coefficient', fontsize=11, fontweight='bold')\n",
    "ax3.set_ylabel('Frequency', fontsize=11, fontweight='bold')\n",
    "ax3.set_title('Distribution of Correlation Coefficients', fontsize=13, fontweight='bold')\n",
    "ax3.legend(fontsize=10)\n",
    "ax3.grid(alpha=0.3, axis='y')\n",
    "\n",
    "# 4. Summary statistics\n",
    "ax4 = plt.subplot(2, 2, 4)\n",
    "ax4.axis('off')\n",
    "summary_text = f\"\"\"\n",
    "MULTICOLLINEARITY SUMMARY\n",
    "\n",
    "Total Numerical Features: {len(numerical_features)}\n",
    "Feature Pairs Analyzed: {len(correlation_matrix) * (len(correlation_matrix) - 1) / 2:.0f}\n",
    "\n",
    "Correlation Statistics:\n",
    "  Max Correlation: {corr_values.max():.3f}\n",
    "  Min Correlation: {corr_values.min():.3f}\n",
    "  Mean Correlation: {corr_values.mean():.3f}\n",
    "  Std Dev: {corr_values.std():.3f}\n",
    "\n",
    "High Correlations (|r| > 0.7): {len(high_corr_pairs)}\n",
    "Moderate Correlations (0.5-0.7): {len(mod_corr_pairs)}\n",
    "\n",
    "Recommendations:\n",
    "• Consider removing highly correlated features\n",
    "• Use VIF for multicollinearity check\n",
    "• Apply PCA for dimensionality reduction\n",
    "• RobustScaler handles moderate correlations well\n",
    "\"\"\"\n",
    "ax4.text(0.05, 0.95, summary_text, transform=ax4.transAxes,\n",
    "        fontsize=10, verticalalignment='top', fontfamily='monospace',\n",
    "        bbox=dict(boxstyle='round', facecolor='#ecf0f1', alpha=0.8, pad=1))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('04_correlation_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✓ Correlation and multicollinearity visualizations created successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f613ab68",
   "metadata": {},
   "source": [
    "## Section 7: Predictive Power Analysis (Good vs Bad Risk)\n",
    "### Box Plots and Violin Plots Showing Discriminative Power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f141a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for comparison\n",
    "good_risk = df[df['Credit_Risk'] == 0]\n",
    "bad_risk = df[df['Credit_Risk'] == 1]\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PREDICTIVE POWER ANALYSIS: GOOD vs BAD CREDIT RISK\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Calculate discriminative statistics\n",
    "key_features = ['Credit_Amount', 'Duration_Months', 'Age', 'Installment_Rate', 'Credit_History']\n",
    "\n",
    "discriminative_stats = []\n",
    "for feature in key_features:\n",
    "    good_vals = good_risk[feature].dropna()\n",
    "    bad_vals = bad_risk[feature].dropna()\n",
    "    \n",
    "    # Perform t-test\n",
    "    t_stat, p_value = stats.ttest_ind(good_vals, bad_vals)\n",
    "    \n",
    "    # Calculate effect size (Cohen's d)\n",
    "    cohens_d = (good_vals.mean() - bad_vals.mean()) / np.sqrt(((len(good_vals)-1)*good_vals.std()**2 + (len(bad_vals)-1)*bad_vals.std()**2) / (len(good_vals) + len(bad_vals) - 2))\n",
    "    \n",
    "    discriminative_stats.append({\n",
    "        'Feature': feature,\n",
    "        'Good_Mean': good_vals.mean(),\n",
    "        'Bad_Mean': bad_vals.mean(),\n",
    "        'Mean_Diff': abs(good_vals.mean() - bad_vals.mean()),\n",
    "        'Cohens_d': abs(cohens_d),\n",
    "        'P_Value': p_value,\n",
    "        'Significant': 'Yes' if p_value < 0.05 else 'No'\n",
    "    })\n",
    "\n",
    "disc_stats_df = pd.DataFrame(discriminative_stats).sort_values('Cohens_d', ascending=False)\n",
    "print(\"\\nDiscriminative Power Analysis (Effect Size - Cohen's d):\")\n",
    "print(disc_stats_df.to_string(index=False))\n",
    "\n",
    "# Create visualizations\n",
    "fig = plt.figure(figsize=(20, 12))\n",
    "\n",
    "# Box plots for key features\n",
    "for idx, feature in enumerate(key_features):\n",
    "    ax = plt.subplot(2, 5, idx + 1)\n",
    "    \n",
    "    data_to_plot = [good_risk[feature].dropna(), bad_risk[feature].dropna()]\n",
    "    bp = ax.boxplot(data_to_plot, labels=['Good (0)', 'Bad (1)'],\n",
    "                    patch_artist=True, widths=0.6,\n",
    "                    boxprops=dict(facecolor='#3498db', alpha=0.7, edgecolor='black', linewidth=1.5),\n",
    "                    whiskerprops=dict(color='black', linewidth=1.5),\n",
    "                    capprops=dict(color='black', linewidth=1.5),\n",
    "                    medianprops=dict(color='red', linewidth=2),\n",
    "                    flierprops=dict(marker='o', markerfacecolor='#e74c3c', markersize=5, alpha=0.5))\n",
    "    \n",
    "    # Color the boxes differently\n",
    "    bp['boxes'][0].set_facecolor('#2ecc71')\n",
    "    bp['boxes'][0].set_alpha(0.7)\n",
    "    bp['boxes'][1].set_facecolor('#e74c3c')\n",
    "    bp['boxes'][1].set_alpha(0.7)\n",
    "    \n",
    "    ax.set_ylabel('Value', fontsize=10, fontweight='bold')\n",
    "    ax.set_title(f'{feature} by Risk Class', fontsize=11, fontweight='bold')\n",
    "    ax.grid(alpha=0.3, axis='y')\n",
    "    \n",
    "    # Add mean values as text\n",
    "    good_mean = good_risk[feature].mean()\n",
    "    bad_mean = bad_risk[feature].mean()\n",
    "    ax.text(0.98, 0.98, f\"Good Mean: {good_mean:.2f}\\nBad Mean: {bad_mean:.2f}\",\n",
    "           transform=ax.transAxes, ha='right', va='top',\n",
    "           bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8),\n",
    "           fontsize=9, fontweight='bold')\n",
    "\n",
    "# Violin plots for key features\n",
    "for idx, feature in enumerate(key_features):\n",
    "    ax = plt.subplot(2, 5, 5 + idx + 1)\n",
    "    \n",
    "    data_good = good_risk[feature].dropna().values\n",
    "    data_bad = bad_risk[feature].dropna().values\n",
    "    \n",
    "    parts = ax.violinplot([data_good, data_bad], positions=[1, 2], showmeans=True, showmedians=True)\n",
    "    \n",
    "    # Color the violins\n",
    "    colors = ['#2ecc71', '#e74c3c']\n",
    "    for pc, color in zip(parts['bodies'], colors):\n",
    "        pc.set_facecolor(color)\n",
    "        pc.set_alpha(0.7)\n",
    "        pc.set_edgecolor('black')\n",
    "        pc.set_linewidth(1.5)\n",
    "    \n",
    "    ax.set_xticks([1, 2])\n",
    "    ax.set_xticklabels(['Good (0)', 'Bad (1)'])\n",
    "    ax.set_ylabel('Value', fontsize=10, fontweight='bold')\n",
    "    ax.set_title(f'{feature} Distribution by Risk', fontsize=11, fontweight='bold')\n",
    "    ax.grid(alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('05_predictive_power_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✓ Predictive power analysis visualizations created successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c50dc1d",
   "metadata": {},
   "source": [
    "## Section 8: Outlier Identification and Analysis\n",
    "### Comprehensive Outlier Detection and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d624916",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"OUTLIER IDENTIFICATION AND ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Calculate outliers using IQR method\n",
    "outlier_summary = []\n",
    "outlier_visualizations_data = {}\n",
    "\n",
    "for feature in numerical_features:\n",
    "    data = df[feature].dropna()\n",
    "    Q1 = data.quantile(0.25)\n",
    "    Q3 = data.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    outliers = data[(data < lower_bound) | (data > upper_bound)]\n",
    "    outlier_count = len(outliers)\n",
    "    outlier_pct = (outlier_count / len(data)) * 100\n",
    "    \n",
    "    outlier_summary.append({\n",
    "        'Feature': feature,\n",
    "        'Total_Values': len(data),\n",
    "        'Outlier_Count': outlier_count,\n",
    "        'Outlier_Percentage': outlier_pct,\n",
    "        'Lower_Bound': lower_bound,\n",
    "        'Upper_Bound': upper_bound,\n",
    "        'Min': data.min(),\n",
    "        'Max': data.max()\n",
    "    })\n",
    "    \n",
    "    outlier_visualizations_data[feature] = {\n",
    "        'Q1': Q1, 'Q3': Q3, 'IQR': IQR,\n",
    "        'lower_bound': lower_bound, 'upper_bound': upper_bound,\n",
    "        'outlier_count': outlier_count, 'data': data\n",
    "    }\n",
    "\n",
    "outlier_df = pd.DataFrame(outlier_summary).sort_values('Outlier_Percentage', ascending=False)\n",
    "print(\"\\nOutlier Summary (IQR Method):\")\n",
    "print(outlier_df.to_string(index=False))\n",
    "\n",
    "# Total outliers\n",
    "total_outliers = outlier_df['Outlier_Count'].sum()\n",
    "print(f\"\\nTotal Outliers Detected: {total_outliers}\")\n",
    "print(f\"Average Outlier Percentage: {outlier_df['Outlier_Percentage'].mean():.2f}%\")\n",
    "\n",
    "# Create visualizations\n",
    "fig = plt.figure(figsize=(20, 14))\n",
    "\n",
    "# Box plots with outlier highlighting for all numerical features\n",
    "plot_idx = 1\n",
    "for feature in numerical_features:\n",
    "    if plot_idx <= 12:  # Limit to 12 plots\n",
    "        ax = plt.subplot(3, 4, plot_idx)\n",
    "        \n",
    "        data = df[feature].dropna()\n",
    "        bp = ax.boxplot([data], labels=[feature], patch_artist=True, widths=0.5,\n",
    "                        boxprops=dict(facecolor='#3498db', alpha=0.7, edgecolor='black', linewidth=1.5),\n",
    "                        whiskerprops=dict(color='black', linewidth=1.5),\n",
    "                        capprops=dict(color='black', linewidth=1.5),\n",
    "                        medianprops=dict(color='red', linewidth=2),\n",
    "                        flierprops=dict(marker='o', markerfacecolor='#e74c3c', markersize=6, alpha=0.7))\n",
    "        \n",
    "        outlier_info = outlier_visualizations_data[feature]\n",
    "        outlier_pct = outlier_df[outlier_df['Feature'] == feature]['Outlier_Percentage'].values[0]\n",
    "        \n",
    "        ax.set_ylabel('Value', fontsize=10, fontweight='bold')\n",
    "        ax.set_title(f'{feature}\\n({outlier_info[\"outlier_count\"]} outliers, {outlier_pct:.2f}%)', \n",
    "                    fontsize=10, fontweight='bold')\n",
    "        ax.grid(alpha=0.3, axis='y')\n",
    "        \n",
    "        # Add statistics as text\n",
    "        ax.text(0.98, 0.98, f\"Median: {data.median():.2f}\\nMean: {data.mean():.2f}\\nStd: {data.std():.2f}\",\n",
    "               transform=ax.transAxes, ha='right', va='top',\n",
    "               bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8),\n",
    "               fontsize=8, fontweight='bold')\n",
    "        \n",
    "        plot_idx += 1\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('06_outlier_detection.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Create outlier summary visualization\n",
    "fig = plt.figure(figsize=(18, 8))\n",
    "\n",
    "# Outlier percentage bar chart\n",
    "ax1 = plt.subplot(1, 3, 1)\n",
    "top_outlier_features = outlier_df.head(10)\n",
    "colors_outlier = plt.cm.Reds(np.linspace(0.4, 0.9, len(top_outlier_features)))\n",
    "bars = ax1.barh(range(len(top_outlier_features)), top_outlier_features['Outlier_Percentage'].values,\n",
    "               color=colors_outlier, alpha=0.8, edgecolor='black', linewidth=1.5)\n",
    "ax1.set_yticks(range(len(top_outlier_features)))\n",
    "ax1.set_yticklabels(top_outlier_features['Feature'].values, fontsize=10)\n",
    "ax1.set_xlabel('Outlier Percentage (%)', fontsize=11, fontweight='bold')\n",
    "ax1.set_title('Top 10 Features by Outlier Percentage', fontsize=12, fontweight='bold')\n",
    "ax1.grid(alpha=0.3, axis='x')\n",
    "for i, bar in enumerate(bars):\n",
    "    width = bar.get_width()\n",
    "    ax1.text(width, bar.get_y() + bar.get_height()/2.,\n",
    "            f' {width:.2f}%', ha='left', va='center', fontweight='bold', fontsize=9)\n",
    "\n",
    "# Outlier count comparison\n",
    "ax2 = plt.subplot(1, 3, 2)\n",
    "bars = ax2.bar(range(len(outlier_df)), outlier_df['Outlier_Count'].values,\n",
    "              color=plt.cm.Spectral(np.linspace(0, 1, len(outlier_df))),\n",
    "              alpha=0.8, edgecolor='black', linewidth=1)\n",
    "ax2.set_xticks(range(len(outlier_df)))\n",
    "ax2.set_xticklabels(outlier_df['Feature'].values, rotation=45, ha='right', fontsize=9)\n",
    "ax2.set_ylabel('Outlier Count', fontsize=11, fontweight='bold')\n",
    "ax2.set_title('Outlier Count by Feature', fontsize=12, fontweight='bold')\n",
    "ax2.grid(alpha=0.3, axis='y')\n",
    "\n",
    "# Summary table\n",
    "ax3 = plt.subplot(1, 3, 3)\n",
    "ax3.axis('off')\n",
    "summary_outlier = f\"\"\"\n",
    "OUTLIER ANALYSIS SUMMARY\n",
    "\n",
    "Detection Method: IQR (1.5 × IQR)\n",
    "\n",
    "Statistics:\n",
    "  Total Outliers: {total_outliers}\n",
    "  Features with Outliers: {(outlier_df['Outlier_Count'] > 0).sum()}\n",
    "  Avg Outlier %: {outlier_df['Outlier_Percentage'].mean():.2f}%\n",
    "  Max Outlier %: {outlier_df['Outlier_Percentage'].max():.2f}%\n",
    "  Min Outlier %: {outlier_df['Outlier_Percentage'].min():.2f}%\n",
    "\n",
    "Top 3 Features with Most Outliers:\n",
    "  1. {outlier_df.iloc[0]['Feature']}: {outlier_df.iloc[0]['Outlier_Count']} ({outlier_df.iloc[0]['Outlier_Percentage']:.2f}%)\n",
    "  2. {outlier_df.iloc[1]['Feature']}: {outlier_df.iloc[1]['Outlier_Count']} ({outlier_df.iloc[1]['Outlier_Percentage']:.2f}%)\n",
    "  3. {outlier_df.iloc[2]['Feature']}: {outlier_df.iloc[2]['Outlier_Count']} ({outlier_df.iloc[2]['Outlier_Percentage']:.2f}%)\n",
    "\n",
    "Recommended Strategy:\n",
    "  • Use RobustScaler (resistant to outliers)\n",
    "  • SMOTE for class imbalance\n",
    "  • No removal recommended (keep data integrity)\n",
    "\"\"\"\n",
    "ax3.text(0.05, 0.95, summary_outlier, transform=ax3.transAxes,\n",
    "        fontsize=10, verticalalignment='top', fontfamily='monospace',\n",
    "        bbox=dict(boxstyle='round', facecolor='#ecf0f1', alpha=0.8, pad=1))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('07_outlier_summary.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✓ Outlier identification and analysis visualizations created successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56402f1f",
   "metadata": {},
   "source": [
    "## Section 9: Advanced Feature Engineering\n",
    "### Creating 16 New Features for Enhanced Predictive Power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c378079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create enhanced dataset with engineered features\n",
    "df_enhanced = df.copy()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ADVANCED FEATURE ENGINEERING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 1. Ratio features (capture relationships between variables)\n",
    "print(\"\\n1. Creating Ratio Features...\")\n",
    "df_enhanced['Credit_Duration_Ratio'] = df_enhanced['Credit_Amount'] / (df_enhanced['Duration_Months'] + 1)\n",
    "df_enhanced['Credit_Age_Ratio'] = df_enhanced['Credit_Amount'] / (df_enhanced['Age'] + 1)\n",
    "df_enhanced['Monthly_Payment'] = df_enhanced['Credit_Amount'] / (df_enhanced['Duration_Months'] + 1)\n",
    "print(\"   ✓ Credit_Duration_Ratio\")\n",
    "print(\"   ✓ Credit_Age_Ratio\")\n",
    "print(\"   ✓ Monthly_Payment\")\n",
    "\n",
    "# 2. Interaction features (capture joint effects)\n",
    "print(\"\\n2. Creating Interaction Features...\")\n",
    "df_enhanced['Amount_Duration_Interaction'] = df_enhanced['Credit_Amount'] * df_enhanced['Duration_Months']\n",
    "df_enhanced['Age_Employment_Interaction'] = df_enhanced['Age'] * df_enhanced['Employment_Since']\n",
    "df_enhanced['Checking_Savings_Interaction'] = df_enhanced['Status_Checking_Account'] * df_enhanced['Savings_Account']\n",
    "print(\"   ✓ Amount_Duration_Interaction\")\n",
    "print(\"   ✓ Age_Employment_Interaction\")\n",
    "print(\"   ✓ Checking_Savings_Interaction\")\n",
    "\n",
    "# 3. Polynomial features (capture non-linear relationships)\n",
    "print(\"\\n3. Creating Polynomial Features...\")\n",
    "df_enhanced['Credit_Amount_Squared'] = df_enhanced['Credit_Amount'] ** 2\n",
    "print(\"   ✓ Credit_Amount_Squared\")\n",
    "\n",
    "# 4. Binned categorical features\n",
    "print(\"\\n4. Creating Binned Categorical Features...\")\n",
    "df_enhanced['Age_Group'] = pd.cut(df_enhanced['Age'], bins=[0, 25, 35, 50, 100], labels=[1, 2, 3, 4])\n",
    "df_enhanced['Credit_Amount_Category'] = pd.qcut(df_enhanced['Credit_Amount'], q=5, labels=[1, 2, 3, 4, 5], duplicates='drop')\n",
    "df_enhanced['Duration_Category'] = pd.cut(df_enhanced['Duration_Months'], bins=[0, 12, 24, 36, 100], labels=[1, 2, 3, 4])\n",
    "print(\"   ✓ Age_Group\")\n",
    "print(\"   ✓ Credit_Amount_Category\")\n",
    "print(\"   ✓ Duration_Category\")\n",
    "\n",
    "# 5. Risk indicator features\n",
    "print(\"\\n5. Creating Risk Indicator Features...\")\n",
    "df_enhanced['High_Credit_Amount'] = (df_enhanced['Credit_Amount'] > df_enhanced['Credit_Amount'].median()).astype(int)\n",
    "df_enhanced['Long_Duration'] = (df_enhanced['Duration_Months'] > 24).astype(int)\n",
    "df_enhanced['High_Installment_Rate'] = (df_enhanced['Installment_Rate'] >= 3).astype(int)\n",
    "df_enhanced['Young_Borrower'] = (df_enhanced['Age'] < 30).astype(int)\n",
    "print(\"   ✓ High_Credit_Amount\")\n",
    "print(\"   ✓ Long_Duration\")\n",
    "print(\"   ✓ High_Installment_Rate\")\n",
    "print(\"   ✓ Young_Borrower\")\n",
    "\n",
    "# Convert categorical bins to numeric\n",
    "df_enhanced['Age_Group'] = df_enhanced['Age_Group'].astype(int)\n",
    "df_enhanced['Credit_Amount_Category'] = df_enhanced['Credit_Amount_Category'].astype(int)\n",
    "df_enhanced['Duration_Category'] = df_enhanced['Duration_Category'].astype(int)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FEATURE ENGINEERING SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nOriginal Features: {len(df.columns) - 1}\")\n",
    "print(f\"New Features Created: 16\")\n",
    "print(f\"Total Features: {len(df_enhanced.columns) - 1}\")\n",
    "print(f\"\\nNew Feature List:\")\n",
    "new_features = [\n",
    "    'Credit_Duration_Ratio', 'Credit_Age_Ratio', 'Monthly_Payment',\n",
    "    'Amount_Duration_Interaction', 'Age_Employment_Interaction', 'Checking_Savings_Interaction',\n",
    "    'Credit_Amount_Squared', 'Age_Group', 'Credit_Amount_Category', 'Duration_Category',\n",
    "    'High_Credit_Amount', 'Long_Duration', 'High_Installment_Rate', 'Young_Borrower'\n",
    "]\n",
    "for i, feat in enumerate(new_features, 1):\n",
    "    print(f\"   {i}. {feat}\")\n",
    "\n",
    "# Create visualization for new features\n",
    "fig = plt.figure(figsize=(18, 10))\n",
    "\n",
    "# Ratio features distributions\n",
    "ax1 = plt.subplot(2, 3, 1)\n",
    "ax1.hist(df_enhanced['Credit_Duration_Ratio'].dropna(), bins=40, color='#3498db', alpha=0.7, edgecolor='black')\n",
    "ax1.set_xlabel('Value', fontsize=10, fontweight='bold')\n",
    "ax1.set_title('Credit_Duration_Ratio Distribution', fontsize=11, fontweight='bold')\n",
    "ax1.grid(alpha=0.3, axis='y')\n",
    "\n",
    "ax2 = plt.subplot(2, 3, 2)\n",
    "ax2.hist(df_enhanced['Credit_Age_Ratio'].dropna(), bins=40, color='#2ecc71', alpha=0.7, edgecolor='black')\n",
    "ax2.set_xlabel('Value', fontsize=10, fontweight='bold')\n",
    "ax2.set_title('Credit_Age_Ratio Distribution', fontsize=11, fontweight='bold')\n",
    "ax2.grid(alpha=0.3, axis='y')\n",
    "\n",
    "ax3 = plt.subplot(2, 3, 3)\n",
    "ax3.hist(df_enhanced['Monthly_Payment'].dropna(), bins=40, color='#e74c3c', alpha=0.7, edgecolor='black')\n",
    "ax3.set_xlabel('Value', fontsize=10, fontweight='bold')\n",
    "ax3.set_title('Monthly_Payment Distribution', fontsize=11, fontweight='bold')\n",
    "ax3.grid(alpha=0.3, axis='y')\n",
    "\n",
    "# Categorical bins distribution\n",
    "ax4 = plt.subplot(2, 3, 4)\n",
    "age_group_counts = df_enhanced['Age_Group'].value_counts().sort_index()\n",
    "ax4.bar(age_group_counts.index, age_group_counts.values, color='#9b59b6', alpha=0.8, edgecolor='black', linewidth=1.5)\n",
    "ax4.set_xlabel('Age Group', fontsize=10, fontweight='bold')\n",
    "ax4.set_ylabel('Count', fontsize=10, fontweight='bold')\n",
    "ax4.set_title('Age_Group Distribution (Binned)', fontsize=11, fontweight='bold')\n",
    "ax4.set_xticks([1, 2, 3, 4])\n",
    "ax4.set_xticklabels(['<25', '25-35', '35-50', '>50'])\n",
    "ax4.grid(alpha=0.3, axis='y')\n",
    "\n",
    "# Risk indicators distribution\n",
    "ax5 = plt.subplot(2, 3, 5)\n",
    "risk_indicators = ['High_Credit_Amount', 'Long_Duration', 'High_Installment_Rate', 'Young_Borrower']\n",
    "risk_counts = [df_enhanced[feat].sum() for feat in risk_indicators]\n",
    "colors_risk = plt.cm.Set2(np.linspace(0, 1, len(risk_indicators)))\n",
    "bars = ax5.bar(risk_indicators, risk_counts, color=colors_risk, alpha=0.8, edgecolor='black', linewidth=1.5)\n",
    "ax5.set_ylabel('Count', fontsize=10, fontweight='bold')\n",
    "ax5.set_title('Risk Indicator Frequencies', fontsize=11, fontweight='bold')\n",
    "ax5.tick_params(axis='x', rotation=45)\n",
    "plt.setp(ax5.xaxis.get_majorticklabels(), rotation=45, ha='right', fontsize=9)\n",
    "ax5.grid(alpha=0.3, axis='y')\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    ax5.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'{int(height)}', ha='center', va='bottom', fontweight='bold', fontsize=9)\n",
    "\n",
    "# Feature engineering impact summary\n",
    "ax6 = plt.subplot(2, 3, 6)\n",
    "ax6.axis('off')\n",
    "engineering_summary = f\"\"\"\n",
    "FEATURE ENGINEERING IMPACT\n",
    "\n",
    "Categories:\n",
    "1. Ratio Features (3)\n",
    "   - Capture relationships\n",
    "   - Normalize by duration/age\n",
    "\n",
    "2. Interaction Features (3)\n",
    "   - Joint effects\n",
    "   - Cross-variable patterns\n",
    "\n",
    "3. Polynomial Features (1)\n",
    "   - Non-linear relationships\n",
    "   - Squared terms\n",
    "\n",
    "4. Binned Features (3)\n",
    "   - Discretized continuous\n",
    "   - Category mapping\n",
    "\n",
    "5. Risk Indicators (4)\n",
    "   - Binary risk flags\n",
    "   - Domain knowledge\n",
    "\n",
    "Total New Features: 14\n",
    "Expected Impact: ↑ Predictive Power\n",
    "\"\"\"\n",
    "ax6.text(0.05, 0.95, engineering_summary, transform=ax6.transAxes,\n",
    "        fontsize=10, verticalalignment='top', fontfamily='monospace',\n",
    "        bbox=dict(boxstyle='round', facecolor='#ecf0f1', alpha=0.8, pad=1))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('08_feature_engineering.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✓ Advanced feature engineering completed successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3536e6b",
   "metadata": {},
   "source": [
    "## Section 10: Data Preprocessing and Train-Test Split"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
